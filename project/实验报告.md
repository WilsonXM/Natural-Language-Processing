<h1 align='center'>基于大语言模型的思维链推理</h1>

<h3 align='center'>Group 20</h3>







[toc]









### 贡献百分比

| 徐铭 | 梅昕宇 | 陈科睿 | 卢峰杰 | 嵇嘉宇 |
| ---- | ------ | ------ | ------ | ------ |
|      |        |        |        |        |



### 实验简介

在lab4的基础上，我们小组对“基于大语言模型的思维链推理“进行了相关进阶探索，我们的探索分为三个部分

* **Part1**:  Multiple Reasoning Paths & Self-Consistency

  >基于《*Self-Consistency Improves Chain of Thought Reasoning in Language Models*》

* **Part2**：针对不同推理路径构建verifier

  > 基于《*Making Large Language Models Better Reasoners with Step-Aware Verifier*》

* **Part3**：使用Retrieval方法为思维链提供先验知识

  * **方法1**: bruteforce
  * **方法2: **精简database
  * **方法3: **Human in the Loop

  > 基于《*Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions*》



**数据集**：*AQuA* https://github.com/deepmind/AQuA





















## Part1：Multiple Reasoning Paths & Self-Consistency

### 1.1 实现原理

对于人类来说，每个人的解决问题的思路是不一样的，对于同一个问题，不同人也会想到不同的解法。自然，我们可以假设对于那些要求复杂思考的问题，LLM也可以得到多种路径去得到答案。一个模型可以生成多种合理的路径去得到正确的答案，但是不合理的路径得到相同错误答案的可能行相较前者来说显然较小。也就是说，我们假设正确的推理过程即使是多样化的，在最终答案上的一致性往往比错误的过程更高。

<img src="https://p-i-c-g-o.oss-cn-hangzhou.aliyuncs.com/img/202406301352049.png" alt="image-20240630134301255" style="zoom:50%;" />

### 1.2 实现过程

具体实验中，我们首先利用chain of thought生成多条推理路径和答案，最终选择出现最多次的答案作为最终答案输出。

<img src="https://p-i-c-g-o.oss-cn-hangzhou.aliyuncs.com/img/202406301405434.png" alt="image-20240629221317419" style="zoom:70%;" />

<img src="https://p-i-c-g-o.oss-cn-hangzhou.aliyuncs.com/img/202406301405526.png" alt="image-20240629221341919" style="zoom:67%;" />

<img src="https://p-i-c-g-o.oss-cn-hangzhou.aliyuncs.com/img/202406301406198.png" alt="image-20240629221354239" style="zoom:67%;" />



### 1.3 实验结果

图中可见，除了for循环使推理重复了num_paths次外，推理的具体过程和正常COT没有什么区别，在num_paths次训练完后，挑选出现次数最多的answer作为最终的预测。

<img src="https://p-i-c-g-o.oss-cn-hangzhou.aliyuncs.com/img/202406301356951.png" alt="image-20240629221519685" style="zoom:60%;" />

由于数据集的数学问题比较复杂以及训练资源有限等原因，我们采取数据集中的前十条，每个问题生成5个COT，最终的准确率是50%。

<img src="https://p-i-c-g-o.oss-cn-hangzhou.aliyuncs.com/img/202406301356421.png" alt="屏幕截图 2024-06-30 134845" style="zoom:50%;" />

与不添加self-consistency的baseline对比，可见accuracy提高了10%，和原论文12%的提高率相近。





### 1.4 方法总结

#### 1.4.1 方法优越性

1、提高准确性

2、提高鲁棒性，通过多条独立的推理路径，即使某些路径由于模型限制或数据噪音导致错误，整体结果仍然可以保持稳定。

3、可以非常简单地与其他优化方法融合

#### 1.4.2 方法局限性

1、计算资源消耗大

2、复杂度增加







## Part2: 针对不同推理路径构建verifier

Making Large Language Models Better Reasoners with Step-Aware Verifier

![image-20240629232314575](https://p-i-c-g-o.oss-cn-hangzhou.aliyuncs.com/img/202406301320131.png)

### 2.1 实现原理

#### 2.1.1 任务定义

在Part1的多条思维链的基础上，增加了对结果的验证环节，即我们这里的Voting Verfier。我们希望通过这里的小模型来实现对推理路径的综合统一，从而得到一个更为准确和合理的答案。

考虑的调用方便的缘故，我们没有使用本地的方案，使用了通义千问的qwen-turbo模型作为verifier。

#### 2.1.2 核心思想

1. **单条路径**：用第一个model（qwen-long）跑cot，然后生成结果，然后让verifier（qwen-turbo）来判断推理是否有误，如果有误，就用这个model重新算一遍，作为结果，然后计算准确率。

   ![image-20240629233550685](https://p-i-c-g-o.oss-cn-hangzhou.aliyuncs.com/img/202406301321573.png)

2. **多条路径**：多条路径使用不同的cot得到若干结果进行投票，当发现投票结果不全一样时，则用verifier判断最高得分的选项是否正确，如果不正确，则重新推理一遍，并将答案作为最终推理结果。

   ![image-20240629233626290](https://p-i-c-g-o.oss-cn-hangzhou.aliyuncs.com/img/202406301321136.png)

#### 2.1.3 方法优越性

1. 巧妙利用大小模型协同
2. 使用prompt让另一个LLM快速适应verify任务
3. 多重实验对比，得到性能提升

#### 2.1.4 方法局限性

1. 没能自行训练verifier，与原论文有差异
2. fine-tuning model价格有点昂贵，没能尝试效果如何



### 2.2 实验结果

#### 2.2.1 单条路径

通过单条路径验证结果，准确率60%.

![image-20240629232610544](https://p-i-c-g-o.oss-cn-hangzhou.aliyuncs.com/img/202406301321913.png)

#### 2.2.2 多条路径

通过多条路径推理和验证，准确率70%，高于Part1中仅使用多条路径的准确率（50%）。

![image-20240629232416200](https://p-i-c-g-o.oss-cn-hangzhou.aliyuncs.com/img/202406301321208.png)







## Part3: 使用Retrieval方法为思维链提供先验知识

### 3.1 实现原理

#### 3.1.1 实验动机

​		在前面的Part1与Part2中，我们更多的是利用思维链的结构对生成过程进行优化。在这个过程中我们调用的大模型并没有实质上获得额外的知识。因此在Part3中，我们考虑在思维链中提供一些外部数据库中的先验知识，帮助大模型进行更好的思维推理。

#### 3.1.2 Retrieval方法概述

​		Retrieval方法是大语言模型生成优化中一个非常热门的方法，在许多任务中都取得了非常出色的效果。它们大多用于解决常规的常识问题，例如“中国的首都是哪里”这类问题。就具体流程而言它的过程如下：1.将输入的问题传入检索器中。 2.利用检索器到外部数据库（如wiki等）中进行检索并将检索到的结果与问题以及生成器的输出（如果有）拼接为新的输入。 3.输入给生成器并产生对应的新的输出。 4.将输出的最后一个句子作为新一轮的检索，重复迭代执行1-4过程直至生成器的生成中出现“the answer is”等相关词或是达到最大值时终止该流程。

​		下图为该方法的一个形象性描述：

![clip_image002](https://p-i-c-g-o.oss-cn-hangzhou.aliyuncs.com/img/202406301327959.jpg)

#### 3.1.3 方法迁移及挑战分析

​		Retrieval的方法在常识问题中能够取得非常好的效果，且非常容易进行实现，这是因为常识类问题中往往**信息的逻辑性很低且有效信息（隐含知识）暴露非常直接**，通过简单的**文本匹配**即可得到较好的提示。而本次实验中，我们应对的是逻辑性要求极高的数学计算问题。这类问题它们的有效信息是**隐藏在深层逻辑当中**的，如一个数学题修改了数据后其有效信息其实没有变化，但是在文本表现上就会千差万别。这表明此类问题的有效信息可能需要经过若干轮的转换才能得到，也因此导致了普通的retrieval**检索难度极大**。如若仅使用普通的文本匹配可能未必能够取得理想的效果，这给我们的方法迁移带来了极大的挑战。针对上述挑战我们进行了三个层次上的探索实验，**其中方法2、3相比于Part1、2中的方法取得了较大的提升**。



### 3.2 方法1——bruteforce

​		首先我们考虑使用最简单直接的生搬硬套，对于数学问题**Q1**我们利用搜索引擎，在外部网络数据库中进行检索，并选取相关度最高的k个（实验中k=5），作为问题**Q1**的先验知识。在与生成模型交互时，该先验知识会作为prompt进行输入。具体而言，在输入内容前添加prompt语句：`Here are some relevant information, may be you can first read them`。

#### 3.2.1 问题分析

​		在方法1的实验过程中，我们对问题以及检索到的内容进行了输出，其中一个示例如下所示（由于篇幅原因我对result后面的一些内容进行了删减）：

```
问题：Q: Question: Two friends plan to walk along a 43-km trail, starting at opposite ends of the trail at the same time. If Friend P's rate is 15% faster than Friend Q's, how many kilometers will Friend P have walked when they pass each other? Choices: A: A)21, B: B)21.5, C: C)22, D: D)22.5, E: E)23
检索内容：Result 1: 【电大国开】国家开放大学23春人文英语1-8形考任务...
Result 2: 2023年浙江省高三名校协作体联考解析...
Result 3: 四六级听力真题练习Day15|备考|day|美文_网易订阅...
Result 4: 编英文对话:两个同学打算一起去旅行,从商量目的地到...
Result 5: 国开《人文英语2》形考任务单元自测7答案...
. 
```

​		我们可以看到该问题检索出来的结果非常不理想，可以说是**毫无关联**。我们认为其主要原因在于外部网站的数据信息**噪声过大**，有太多与数学问题毫无关联但是**在文本匹配角度相似度高**的信息。这会给使用基于文本检索的retrieval方法**引入众多无效知识**，带来极大的干扰。针对该问题，我们提出了方法2进行数据去噪的方法，即构建一个**精简版的database**，该数据库中的内容均为数学题，以此一定程度降低无关信息的干扰。同时，在retrieval过程中不再使用简单的问题匹配，而是**关注问题的相似度**，以此来衡量一个数学题是否作为先验提示。



### 3.3 方法2——精简database

​		在方法2中，我们首先构建了适合数学问题求解的数据集。数据集中包含多个数学问题的描述，以及其详细的解答（有详细的解答过程，以此为COT提供更好的知道）。保存格式为yaml文件，其具体格式如下：

![н╒пе╫ьм╪_20240630004825](https://p-i-c-g-o.oss-cn-hangzhou.aliyuncs.com/img/202406301327930.png)

​		完成数据库的构建后，我们考虑如何在新的数据库中进行高效的retrieval。注意到在现实的生活中数学题往往是有类型之分的，相同类型的题目它们的解题方法以及过程常常有异曲同工之妙。该相似性会为我们思维链的如何构建带来极好的引导。因此在检索时，我们考虑采用类型作为key来进行检查。考虑到我们资源的有限性（没法构造问题向量embedding进行向量相似度检查），我们借鉴了Part2中verify的思想，**利用另一个大模型作为我们的相似度评价器（verify）来进行类型相似度检查**。具体而言，对于问题s1，我们遍历数据库中的所有问题s2，构建输入：`Is it possible that the solution's method for problems {s1} and {s2} will be similar (regardless of whether they are both multiple-choice questions)? Just reply me with yes or no`，交给大模型LLM1来获得数据库中的问题s1与实际问题s2的相似度。对于回答为yes的问题，我们进行拼接，最后将拼接结果作为prompt交给生成模型LLM2。

​		该部分核心代码如下（其余部分几乎同baseline）：

![image-20240630133118702](https://p-i-c-g-o.oss-cn-hangzhou.aliyuncs.com/img/202406301331755.png)

#### 3.3.1 问题分析

​		在实验的过程中，我们发现虽然我们对外部数据库进行了有效的精简，但是在retrieval的返回中仍然会有部分与当前问题无关的信息被返回，这会导致**prompt过长**，大模型的生成能力一定程度上会受到这种长上下文的影响。导致该问题发生的主要原因还是在于**相似度评价器（verify）并不能够做到很准确**，如果存在一个专家模型可以高效地对要进行retrieval的所有内容进行筛选并返回，我们有理由相信性能会更好地提升。但是查阅了一些论文，我们目前没有搜到较好的对于数学问题的解决方法。考虑到对于中学数学问题而言，我们人本身其实就是一个训练非常完善的“专家模型”，故考虑使用**Human in the Loop**方法即将人作为retrieval系统中的一环，对数据库信息进行筛选，选择与当前问题相关度最高的k个作为返回。



### 3.4 方法3——Human in the Loop（upper-bound）

​		在方法3中，我们对retrieval过程进行更加进一步的优化。具体而言，将verify模块替换为Human，将人作为retrieval系统中的一环，对数据库信息进行筛选，选择与当前问题相关度最高的k个作为返回。在实验结果中，我们可以明显地感受到该方法带来的准确率的提高，我们也有理由相信在不提升模型性能的基础上，该方法可能是该问题的上界了。

​		代码改进部分如下：

![fig2](https://p-i-c-g-o.oss-cn-hangzhou.aliyuncs.com/img/202406301331606.png)

#### 3.4.1 局限性分析及改进展望

​		虽然方法3取得了非常不错的效果，但是该系统中有了人的参与，这使得其与人工智能的初衷相违背。不过随着大模型的飞速发展，我们有理由相信上述系统中的Human部分未来可以用一个高效的专家模型来进行代替，该模型可以拥有与人一致甚至更强更准确的筛选能力。这也可以成为一个很不错的研究方向，鉴于我们大程的时间有限，便没有继续在这个方向上进行探索，而是给出这个我们认为的当下的理论上界。



### 3.5 实验结果

#### 3.5.1 方法1

对于方法1，我们取得了60%的准确率

![method1](https://p-i-c-g-o.oss-cn-hangzhou.aliyuncs.com/img/202406301326516.png)

#### 3.5.2 方法2

对于方法2，我们取得了80%的准确率（高于Part1、Part2中的任何方法）

![method2](https://p-i-c-g-o.oss-cn-hangzhou.aliyuncs.com/img/202406301326525.png)

#### 3.5.3 方法3

对于方法3，我们取得了90%的准确率（非常之高，我们有理由认为在不改变LLM模型性能的情况下这个可能会是一个理论上的upper-bound）

![method3](https://p-i-c-g-o.oss-cn-hangzhou.aliyuncs.com/img/202406301331893.png)